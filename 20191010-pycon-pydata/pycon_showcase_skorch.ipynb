{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Definition of the pytorch module](#Definition-of-the-pytorch-module)\n",
    "* [Training a classifier](#Training-a-classifier-and-making-predictions)\n",
    "  * [Dataset](#A-toy-binary-classification-task)\n",
    "  * [pytorch module](#Definition-of-the-pytorch-classification-module)\n",
    "  * [Model training](#Defining-and-training-the-neural-net-classifier)\n",
    "  * [Inference](#Making-predictions,-classification)\n",
    "* [Training a regressor](#Training-a-regressor)\n",
    "  * [Dataset](#A-toy-regression-task)\n",
    "  * [pytorch module](#Definition-of-the-pytorch-regression-module)\n",
    "  * [Model training](#Defining-and-training-the-neural-net-regressor)\n",
    "  * [Inference](#Making-predictions,-regression)\n",
    "* [Saving and loading a model](#Saving-and-loading-a-model)\n",
    "  * [Whole model](#Saving-the-whole-model)\n",
    "  * [Only parameters](#Saving-only-the-model-parameters)\n",
    "* [Usage with an sklearn Pipeline](#Usage-with-an-sklearn-Pipeline)\n",
    "* [Callbacks](#Callbacks)\n",
    "* [Grid search](#Usage-with-sklearn-GridSearchCV)\n",
    "  * [Special prefixes](#Special-prefixes)\n",
    "  * [Performing a grid search](#Performing-a-grid-search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a classifier and making predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A toy binary classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load a toy classification task from `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(1000, 20, n_informative=10, random_state=0)\n",
    "X, y = shuffle(X, y, random_state=0)\n",
    "X = X.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 20), (1000,), 0.5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape, y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of the `pytorch` classification `module`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a vanilla neural network with two hidden layers. The output layer should have 2 output units since there are two classes. In addition, it should have a softmax nonlinearity, because later, when calling `predict_proba`, the output from the `forward` call will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_units=10,\n",
    "            nonlin=F.relu,\n",
    "            dropout=0.5,\n",
    "    ):\n",
    "        super(ClassifierModule, self).__init__()\n",
    "        self.num_units = num_units\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.reset_params()\n",
    "        \n",
    "    def reset_params(self):\n",
    "        self.dense0 = nn.Linear(20, self.num_units)\n",
    "        self.nonlin = self.nonlin\n",
    "        self.dropout = nn.Dropout(self.dropout)\n",
    "        self.dense1 = nn.Linear(self.num_units, 10)\n",
    "        self.output = nn.Linear(10, 2)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = self.dropout(X)\n",
    "        X = F.relu(self.dense1(X))\n",
    "        X = F.softmax(self.output(X), dim=-1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining and training the neural net classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `NeuralNetClassifier` because we're dealing with a classifcation task. The first argument should be the `pytorch module`. As additional arguments, we pass the number of epochs and the learning rate (`lr`), but those are optional.\n",
    "\n",
    "*Note*: To use the CUDA backend, pass `device='cuda'` as an additional argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch import NeuralNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    ClassifierModule,\n",
    "    max_epochs=20,\n",
    "    lr=0.1,\n",
    "    batch_size=64,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in `sklearn`, we call `fit` passing the input data `X` and the targets `y`. By default, `NeuralNetClassifier` makes a `StratifiedKFold` split on the data (80/20) to track the validation loss. This is shown, as well as the train loss and the accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6993\u001b[0m       \u001b[32m0.4700\u001b[0m        \u001b[35m0.6963\u001b[0m  0.0215\n",
      "      2        \u001b[36m0.6876\u001b[0m       \u001b[32m0.5200\u001b[0m        \u001b[35m0.6855\u001b[0m  0.0222\n",
      "      3        \u001b[36m0.6793\u001b[0m       \u001b[32m0.5550\u001b[0m        \u001b[35m0.6804\u001b[0m  0.0220\n",
      "      4        \u001b[36m0.6707\u001b[0m       \u001b[32m0.5950\u001b[0m        \u001b[35m0.6735\u001b[0m  0.0200\n",
      "      5        \u001b[36m0.6630\u001b[0m       \u001b[32m0.6650\u001b[0m        \u001b[35m0.6626\u001b[0m  0.0243\n",
      "      6        \u001b[36m0.6447\u001b[0m       \u001b[32m0.6750\u001b[0m        \u001b[35m0.6495\u001b[0m  0.0203\n",
      "      7        \u001b[36m0.6334\u001b[0m       \u001b[32m0.7200\u001b[0m        \u001b[35m0.6325\u001b[0m  0.0225\n",
      "      8        \u001b[36m0.6301\u001b[0m       0.7000        \u001b[35m0.6201\u001b[0m  0.0210\n",
      "      9        \u001b[36m0.6154\u001b[0m       0.7100        \u001b[35m0.6061\u001b[0m  0.0206\n",
      "     10        \u001b[36m0.6068\u001b[0m       0.7200        \u001b[35m0.5946\u001b[0m  0.0235\n",
      "     11        \u001b[36m0.5917\u001b[0m       0.7150        \u001b[35m0.5929\u001b[0m  0.0210\n",
      "     12        \u001b[36m0.5844\u001b[0m       \u001b[32m0.7350\u001b[0m        \u001b[35m0.5758\u001b[0m  0.0224\n",
      "     13        0.5876       0.7100        0.5781  0.0211\n",
      "     14        \u001b[36m0.5654\u001b[0m       \u001b[32m0.7550\u001b[0m        \u001b[35m0.5596\u001b[0m  0.0204\n",
      "     15        0.5681       0.7550        \u001b[35m0.5533\u001b[0m  0.0245\n",
      "     16        \u001b[36m0.5496\u001b[0m       0.7450        \u001b[35m0.5418\u001b[0m  0.0212\n",
      "     17        0.5553       0.7450        \u001b[35m0.5385\u001b[0m  0.0205\n",
      "     18        0.5672       0.7300        0.5387  0.0241\n",
      "     19        0.5538       0.7500        \u001b[35m0.5328\u001b[0m  0.0226\n",
      "     20        \u001b[36m0.5360\u001b[0m       0.7550        \u001b[35m0.5243\u001b[0m  0.0198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=ClassifierModule(\n",
       "    (dense0): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (dense1): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (output): Linear(in_features=10, out_features=2, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, as in `sklearn`, you may call `predict` or `predict_proba` on the fitted model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions, classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = net.predict(X[:5])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5861401 , 0.4138599 ],\n",
       "       [0.72167945, 0.2783205 ],\n",
       "       [0.16547886, 0.8345211 ],\n",
       "       [0.6584326 , 0.34156734],\n",
       "       [0.48462617, 0.5153738 ]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba = net.predict_proba(X[:5])\n",
    "y_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A toy regression task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_regr, y_regr = make_regression(1000, 20, n_informative=10, random_state=0)\n",
    "X_regr = X_regr.astype(np.float32)\n",
    "y_regr = y_regr.astype(np.float32) / 100\n",
    "y_regr = y_regr.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 20), (1000, 1), -6.4901485, 6.154505)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_regr.shape, y_regr.shape, y_regr.min(), y_regr.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: Regression currently requires the target to be 2-dimensional, hence the need to reshape. This should be fixed with an upcoming version of pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of the `pytorch` regression `module`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, define a vanilla neural network with two hidden layers. The main difference is that the output layer only has one unit and does not apply a softmax nonlinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressorModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_units=10,\n",
    "            nonlin=F.relu,\n",
    "    ):\n",
    "        super(RegressorModule, self).__init__()\n",
    "        self.num_units = num_units\n",
    "        self.nonlin = nonlin\n",
    "        \n",
    "        self.reset_params()\n",
    "\n",
    "    def reset_params(self):\n",
    "        self.dense0 = nn.Linear(20, self.num_units)\n",
    "        self.nonlin = self.nonlin\n",
    "        self.dense1 = nn.Linear(self.num_units, 10)\n",
    "        self.output = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = F.relu(self.dense1(X))\n",
    "        X = self.output(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining and training the neural net regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a regressor is almost the same as training a classifier. Mainly, we use `NeuralNetRegressor` instead of `NeuralNetClassifier` (this is the same terminology as in `sklearn`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch import NeuralNetRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_regr = NeuralNetRegressor(\n",
    "    RegressorModule,\n",
    "    max_epochs=20,\n",
    "    lr=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.5682\u001b[0m        \u001b[32m3.6729\u001b[0m  0.0261\n",
      "      2        \u001b[36m3.3615\u001b[0m        \u001b[32m1.3144\u001b[0m  0.0225\n",
      "      3        \u001b[36m0.9085\u001b[0m        \u001b[32m0.5791\u001b[0m  0.0230\n",
      "      4        0.9227        0.8074  0.0192\n",
      "      5        \u001b[36m0.5005\u001b[0m        \u001b[32m0.1180\u001b[0m  0.0211\n",
      "      6        \u001b[36m0.1183\u001b[0m        \u001b[32m0.1098\u001b[0m  0.0224\n",
      "      7        \u001b[36m0.0984\u001b[0m        \u001b[32m0.0692\u001b[0m  0.0196\n",
      "      8        \u001b[36m0.0653\u001b[0m        \u001b[32m0.0638\u001b[0m  0.0236\n",
      "      9        \u001b[36m0.0531\u001b[0m        \u001b[32m0.0529\u001b[0m  0.0167\n",
      "     10        \u001b[36m0.0400\u001b[0m        \u001b[32m0.0460\u001b[0m  0.0212\n",
      "     11        \u001b[36m0.0318\u001b[0m        \u001b[32m0.0381\u001b[0m  0.0216\n",
      "     12        \u001b[36m0.0253\u001b[0m        \u001b[32m0.0321\u001b[0m  0.0166\n",
      "     13        \u001b[36m0.0207\u001b[0m        \u001b[32m0.0272\u001b[0m  0.0186\n",
      "     14        \u001b[36m0.0173\u001b[0m        \u001b[32m0.0236\u001b[0m  0.0219\n",
      "     15        \u001b[36m0.0147\u001b[0m        \u001b[32m0.0210\u001b[0m  0.0220\n",
      "     16        \u001b[36m0.0129\u001b[0m        \u001b[32m0.0189\u001b[0m  0.0178\n",
      "     17        \u001b[36m0.0115\u001b[0m        \u001b[32m0.0173\u001b[0m  0.0236\n",
      "     18        \u001b[36m0.0105\u001b[0m        \u001b[32m0.0161\u001b[0m  0.0169\n",
      "     19        \u001b[36m0.0097\u001b[0m        \u001b[32m0.0150\u001b[0m  0.0206\n",
      "     20        \u001b[36m0.0089\u001b[0m        \u001b[32m0.0141\u001b[0m  0.0244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.regressor.NeuralNetRegressor'>[initialized](\n",
       "  module_=RegressorModule(\n",
       "    (dense0): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (dense1): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (output): Linear(in_features=10, out_features=1, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_regr.fit(X_regr, y_regr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions, regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may call `predict` or `predict_proba` on the fitted model. For regressions, both methods return the same value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.6712743 ],\n",
       "       [-1.5348388 ],\n",
       "       [-0.7909038 ],\n",
       "       [-0.23888807],\n",
       "       [-0.73821217]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = net_regr.predict(X_regr[:5])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save and load either the whole model by using pickle or just the learned model parameters by calling `save_params` and `load_params`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '/tmp/mymodel.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bbossan/anaconda3/envs/skorch/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type ClassifierModule. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump(net, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_name, 'rb') as f:\n",
    "    new_net = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving only the model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This only saves and loads the proper `module` parameters, meaning that hyperparameters such as `lr` and `max_epochs` are not saved. Therefore, to load the model, we have to re-initialize it beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.save_params(f_params=file_name)  # a file handler also works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first initialize the model\n",
    "new_net = NeuralNetClassifier(\n",
    "    ClassifierModule,\n",
    "    max_epochs=20,\n",
    "    lr=0.1,\n",
    ").initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_net.load_params(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage within an `sklearn Pipeline`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to put the `NeuralNetClassifier` inside an `sklearn Pipeline`, as you would with any `sklearn` classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('net', net),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6959\u001b[0m       \u001b[32m0.5050\u001b[0m        \u001b[35m0.6905\u001b[0m  0.0202\n",
      "      2        \u001b[36m0.6904\u001b[0m       \u001b[32m0.5200\u001b[0m        \u001b[35m0.6856\u001b[0m  0.0243\n",
      "      3        \u001b[36m0.6866\u001b[0m       \u001b[32m0.5500\u001b[0m        \u001b[35m0.6812\u001b[0m  0.0215\n",
      "      4        \u001b[36m0.6747\u001b[0m       \u001b[32m0.5950\u001b[0m        \u001b[35m0.6749\u001b[0m  0.0202\n",
      "      5        \u001b[36m0.6734\u001b[0m       \u001b[32m0.6200\u001b[0m        \u001b[35m0.6684\u001b[0m  0.0264\n",
      "      6        \u001b[36m0.6669\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6610\u001b[0m  0.0206\n",
      "      7        0.6693       \u001b[32m0.6300\u001b[0m        \u001b[35m0.6539\u001b[0m  0.0212\n",
      "      8        \u001b[36m0.6419\u001b[0m       \u001b[32m0.6450\u001b[0m        \u001b[35m0.6423\u001b[0m  0.0249\n",
      "      9        0.6467       \u001b[32m0.6550\u001b[0m        \u001b[35m0.6339\u001b[0m  0.0202\n",
      "     10        \u001b[36m0.6323\u001b[0m       \u001b[32m0.6750\u001b[0m        \u001b[35m0.6217\u001b[0m  0.0237\n",
      "     11        \u001b[36m0.6170\u001b[0m       \u001b[32m0.6950\u001b[0m        \u001b[35m0.6092\u001b[0m  0.0217\n",
      "     12        \u001b[36m0.6154\u001b[0m       \u001b[32m0.7000\u001b[0m        \u001b[35m0.5980\u001b[0m  0.0202\n",
      "     13        0.6159       \u001b[32m0.7100\u001b[0m        \u001b[35m0.5921\u001b[0m  0.0220\n",
      "     14        \u001b[36m0.6015\u001b[0m       0.7100        \u001b[35m0.5835\u001b[0m  0.0208\n",
      "     15        \u001b[36m0.5857\u001b[0m       \u001b[32m0.7350\u001b[0m        \u001b[35m0.5723\u001b[0m  0.0208\n",
      "     16        0.5905       \u001b[32m0.7400\u001b[0m        \u001b[35m0.5671\u001b[0m  0.0230\n",
      "     17        0.5947       0.7350        \u001b[35m0.5601\u001b[0m  0.0209\n",
      "     18        \u001b[36m0.5718\u001b[0m       0.7350        \u001b[35m0.5500\u001b[0m  0.0204\n",
      "     19        0.5754       0.7400        \u001b[35m0.5435\u001b[0m  0.0225\n",
      "     20        \u001b[36m0.5598\u001b[0m       0.7350        \u001b[35m0.5363\u001b[0m  0.0213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scale',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('net',\n",
       "                 <class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=ClassifierModule(\n",
       "    (dense0): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (dense1): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (output): Linear(in_features=10, out_features=2, bias=True)\n",
       "  ),\n",
       "))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49605048, 0.50394946],\n",
       "       [0.63571143, 0.3642885 ],\n",
       "       [0.14369418, 0.8563058 ],\n",
       "       [0.6404413 , 0.35955864],\n",
       "       [0.5492111 , 0.45078892]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba = pipe.predict_proba(X[:5])\n",
    "y_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save the whole pipeline, including the `StandardScaler` and the pytorch module, use `pickle`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a new callback to the model is straightforward. Below we show how to add a new callback that determines the area under the ROC (AUC) score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.callbacks import EpochScoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our case here, since `sklearn` already implements AUC, we just pass the correct string `'roc_auc'`. We should also tell the callback that higher scores are better (to get the correct colors printed below -- by default, lower scores are assumed to be better). Furthermore, we may specify a `name` argument for `EpochScoring`, and whether to use training data (by setting `on_train=True`) or validation data (which is the default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = EpochScoring(scoring='roc_auc', lower_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we pass the scoring callback to the `callbacks` parameter as a list and then call `fit`. Notice that we get the printed scores and color highlighting for free."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    ClassifierModule,\n",
    "    max_epochs=20,\n",
    "    lr=0.1,\n",
    "    callbacks=[auc],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    roc_auc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ---------  ------------  -----------  ------------  ------\n",
      "      1     \u001b[36m0.4326\u001b[0m        \u001b[32m0.7020\u001b[0m       \u001b[35m0.5150\u001b[0m        \u001b[31m0.6973\u001b[0m  0.0165\n",
      "      2     \u001b[36m0.4743\u001b[0m        \u001b[32m0.6964\u001b[0m       0.4650        \u001b[31m0.6941\u001b[0m  0.0184\n",
      "      3     \u001b[36m0.5340\u001b[0m        \u001b[32m0.6954\u001b[0m       \u001b[35m0.5250\u001b[0m        \u001b[31m0.6914\u001b[0m  0.0179\n",
      "      4     \u001b[36m0.5998\u001b[0m        \u001b[32m0.6914\u001b[0m       \u001b[35m0.5700\u001b[0m        \u001b[31m0.6890\u001b[0m  0.0158\n",
      "      5     \u001b[36m0.6478\u001b[0m        \u001b[32m0.6896\u001b[0m       \u001b[35m0.5950\u001b[0m        \u001b[31m0.6858\u001b[0m  0.0177\n",
      "      6     \u001b[36m0.6798\u001b[0m        \u001b[32m0.6830\u001b[0m       0.5900        \u001b[31m0.6821\u001b[0m  0.0173\n",
      "      7     \u001b[36m0.7182\u001b[0m        0.6841       \u001b[35m0.6250\u001b[0m        \u001b[31m0.6779\u001b[0m  0.0186\n",
      "      8     \u001b[36m0.7320\u001b[0m        \u001b[32m0.6777\u001b[0m       \u001b[35m0.6450\u001b[0m        \u001b[31m0.6727\u001b[0m  0.0163\n",
      "      9     \u001b[36m0.7445\u001b[0m        \u001b[32m0.6751\u001b[0m       \u001b[35m0.6750\u001b[0m        \u001b[31m0.6668\u001b[0m  0.0173\n",
      "     10     \u001b[36m0.7560\u001b[0m        \u001b[32m0.6696\u001b[0m       \u001b[35m0.7000\u001b[0m        \u001b[31m0.6579\u001b[0m  0.0156\n",
      "     11     \u001b[36m0.7660\u001b[0m        \u001b[32m0.6562\u001b[0m       \u001b[35m0.7250\u001b[0m        \u001b[31m0.6475\u001b[0m  0.0170\n",
      "     12     \u001b[36m0.7711\u001b[0m        0.6594       0.7200        \u001b[31m0.6396\u001b[0m  0.0160\n",
      "     13     \u001b[36m0.7805\u001b[0m        \u001b[32m0.6454\u001b[0m       \u001b[35m0.7600\u001b[0m        \u001b[31m0.6254\u001b[0m  0.0179\n",
      "     14     \u001b[36m0.7877\u001b[0m        \u001b[32m0.6308\u001b[0m       \u001b[35m0.7700\u001b[0m        \u001b[31m0.6151\u001b[0m  0.0168\n",
      "     15     \u001b[36m0.7924\u001b[0m        \u001b[32m0.6259\u001b[0m       0.7650        \u001b[31m0.6035\u001b[0m  0.0158\n",
      "     16     \u001b[36m0.7947\u001b[0m        \u001b[32m0.6105\u001b[0m       0.7650        \u001b[31m0.5916\u001b[0m  0.0175\n",
      "     17     \u001b[36m0.8069\u001b[0m        \u001b[32m0.6051\u001b[0m       0.7700        \u001b[31m0.5781\u001b[0m  0.0150\n",
      "     18     \u001b[36m0.8109\u001b[0m        \u001b[32m0.5909\u001b[0m       \u001b[35m0.7800\u001b[0m        \u001b[31m0.5635\u001b[0m  0.0167\n",
      "     19     \u001b[36m0.8208\u001b[0m        \u001b[32m0.5869\u001b[0m       0.7750        \u001b[31m0.5527\u001b[0m  0.0152\n",
      "     20     \u001b[36m0.8260\u001b[0m        \u001b[32m0.5787\u001b[0m       0.7800        \u001b[31m0.5450\u001b[0m  0.0163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=ClassifierModule(\n",
       "    (dense0): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (dense1): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (output): Linear(in_features=10, out_features=2, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage with sklearn `GridSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special prefixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `NeuralNet` class allows to directly access parameters of the `pytorch module` by using the `module__` prefix. So e.g. if you defined the `module` to have a `num_units` parameter, you can set it via the `module__num_units` argument. This is exactly the same logic that allows to access estimator parameters in `sklearn Pipeline`s and `FeatureUnion`s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature is useful in several ways. For one, it allows to set those parameters in the model definition. Furthermore, it allows you to set parameters in an `sklearn GridSearchCV` as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the parameters prefixed by `module__`, you may access a couple of other attributes, such as those of the optimizer by using the `optimizer__` prefix (again, see below). All those special prefixes are stored in the `prefixes_` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module, iterator_train, iterator_valid, optimizer, criterion, callbacks, dataset\n"
     ]
    }
   ],
   "source": [
    "print(', '.join(net.prefixes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing a hyperparameter search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we show how to perform a grid search over the learning rate (`lr`), the module's number of hidden units (`module__num_units`), the module's dropout rate (`module__dropout`), and whether the SGD optimizer should use Nesterov momentum or not (`optimizer__nesterov`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    ClassifierModule,\n",
    "    max_epochs=20,\n",
    "    lr=0.1,\n",
    "    verbose=0,\n",
    "    optimizer__momentum=0.9,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'lr': [0.05, 0.1],\n",
    "    'module__num_units': [10, 20],\n",
    "    'module__dropout': [0, 0.5],\n",
    "    'optimizer__nesterov': [False, True],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = RandomizedSearchCV(net, params, refit=False, cv=3, scoring='accuracy', verbose=2, n_iter=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV] optimizer__nesterov=False, module__num_units=10, module__dropout=0.5, lr=0.05 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  optimizer__nesterov=False, module__num_units=10, module__dropout=0.5, lr=0.05, total=   0.3s\n",
      "[CV] optimizer__nesterov=False, module__num_units=10, module__dropout=0.5, lr=0.05 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  optimizer__nesterov=False, module__num_units=10, module__dropout=0.5, lr=0.05, total=   0.2s\n",
      "[CV] optimizer__nesterov=False, module__num_units=10, module__dropout=0.5, lr=0.05 \n",
      "[CV]  optimizer__nesterov=False, module__num_units=10, module__dropout=0.5, lr=0.05, total=   0.4s\n",
      "[CV] optimizer__nesterov=True, module__num_units=20, module__dropout=0.5, lr=0.1 \n",
      "[CV]  optimizer__nesterov=True, module__num_units=20, module__dropout=0.5, lr=0.1, total=   1.1s\n",
      "[CV] optimizer__nesterov=True, module__num_units=20, module__dropout=0.5, lr=0.1 \n",
      "[CV]  optimizer__nesterov=True, module__num_units=20, module__dropout=0.5, lr=0.1, total=   0.6s\n",
      "[CV] optimizer__nesterov=True, module__num_units=20, module__dropout=0.5, lr=0.1 \n",
      "[CV]  optimizer__nesterov=True, module__num_units=20, module__dropout=0.5, lr=0.1, total=   0.5s\n",
      "[CV] optimizer__nesterov=False, module__num_units=20, module__dropout=0.5, lr=0.05 \n",
      "[CV]  optimizer__nesterov=False, module__num_units=20, module__dropout=0.5, lr=0.05, total=   0.5s\n",
      "[CV] optimizer__nesterov=False, module__num_units=20, module__dropout=0.5, lr=0.05 \n",
      "[CV]  optimizer__nesterov=False, module__num_units=20, module__dropout=0.5, lr=0.05, total=   0.8s\n",
      "[CV] optimizer__nesterov=False, module__num_units=20, module__dropout=0.5, lr=0.05 \n",
      "[CV]  optimizer__nesterov=False, module__num_units=20, module__dropout=0.5, lr=0.05, total=   0.8s\n",
      "[CV] optimizer__nesterov=False, module__num_units=10, module__dropout=0.5, lr=0.1 \n",
      "[CV]  optimizer__nesterov=False, module__num_units=10, module__dropout=0.5, lr=0.1, total=   0.3s\n",
      "[CV] optimizer__nesterov=False, module__num_units=10, module__dropout=0.5, lr=0.1 \n",
      "[CV]  optimizer__nesterov=False, module__num_units=10, module__dropout=0.5, lr=0.1, total=   0.5s\n",
      "[CV] optimizer__nesterov=False, module__num_units=10, module__dropout=0.5, lr=0.1 \n",
      "[CV]  optimizer__nesterov=False, module__num_units=10, module__dropout=0.5, lr=0.1, total=   0.3s\n",
      "[CV] optimizer__nesterov=True, module__num_units=10, module__dropout=0, lr=0.05 \n",
      "[CV]  optimizer__nesterov=True, module__num_units=10, module__dropout=0, lr=0.05, total=   0.7s\n",
      "[CV] optimizer__nesterov=True, module__num_units=10, module__dropout=0, lr=0.05 \n",
      "[CV]  optimizer__nesterov=True, module__num_units=10, module__dropout=0, lr=0.05, total=   0.7s\n",
      "[CV] optimizer__nesterov=True, module__num_units=10, module__dropout=0, lr=0.05 \n",
      "[CV]  optimizer__nesterov=True, module__num_units=10, module__dropout=0, lr=0.05, total=   0.5s\n",
      "[CV] optimizer__nesterov=True, module__num_units=20, module__dropout=0, lr=0.1 \n",
      "[CV]  optimizer__nesterov=True, module__num_units=20, module__dropout=0, lr=0.1, total=   0.4s\n",
      "[CV] optimizer__nesterov=True, module__num_units=20, module__dropout=0, lr=0.1 \n",
      "[CV]  optimizer__nesterov=True, module__num_units=20, module__dropout=0, lr=0.1, total=   0.4s\n",
      "[CV] optimizer__nesterov=True, module__num_units=20, module__dropout=0, lr=0.1 \n",
      "[CV]  optimizer__nesterov=True, module__num_units=20, module__dropout=0, lr=0.1, total=   0.6s\n",
      "[CV] optimizer__nesterov=True, module__num_units=20, module__dropout=0.5, lr=0.05 \n",
      "[CV]  optimizer__nesterov=True, module__num_units=20, module__dropout=0.5, lr=0.05, total=   0.3s\n",
      "[CV] optimizer__nesterov=True, module__num_units=20, module__dropout=0.5, lr=0.05 \n",
      "[CV]  optimizer__nesterov=True, module__num_units=20, module__dropout=0.5, lr=0.05, total=   0.3s\n",
      "[CV] optimizer__nesterov=True, module__num_units=20, module__dropout=0.5, lr=0.05 \n",
      "[CV]  optimizer__nesterov=True, module__num_units=20, module__dropout=0.5, lr=0.05, total=   1.2s\n",
      "[CV] optimizer__nesterov=True, module__num_units=20, module__dropout=0, lr=0.05 \n",
      "[CV]  optimizer__nesterov=True, module__num_units=20, module__dropout=0, lr=0.05, total=   1.0s\n",
      "[CV] optimizer__nesterov=True, module__num_units=20, module__dropout=0, lr=0.05 \n",
      "[CV]  optimizer__nesterov=True, module__num_units=20, module__dropout=0, lr=0.05, total=   0.5s\n",
      "[CV] optimizer__nesterov=True, module__num_units=20, module__dropout=0, lr=0.05 \n",
      "[CV]  optimizer__nesterov=True, module__num_units=20, module__dropout=0, lr=0.05, total=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:   13.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=<class 'skorch.classifier.NeuralNetClassifier'>[uninitialized](\n",
       "  module=<class '__main__.ClassifierModule'>,\n",
       "),\n",
       "                   iid='warn', n_iter=8, n_jobs=None,\n",
       "                   param_distributions={'lr': [0.05, 0.1],\n",
       "                                        'module__dropout': [0, 0.5],\n",
       "                                        'module__num_units': [10, 20],\n",
       "                                        'optimizer__nesterov': [False, True]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=False,\n",
       "                   return_train_score=False, scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.855 {'optimizer__nesterov': True, 'module__num_units': 20, 'module__dropout': 0, 'lr': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(search.best_score_, search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we could further nest the `NeuralNetClassifier` within an `sklearn Pipeline`, in which case we just prefix the parameter by the name of the net (e.g. `net__module__num_units`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
